{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dca4377-e05e-44f5-984d-940542aaaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#from abcnre.simulation import ABCSimulator\n",
    "#from abcnre.simulation.models import create_model_from_dict, get_example_model_configs\n",
    "import yaml\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "current_dir = Path().resolve() \n",
    "parent_dir = current_dir.parent    \n",
    "results_dir = parent_dir / \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65260567-97e5-41a3-a268-31336322b834",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ABCSimulator' from 'abcnre.simulation.utils' (/home/rgiordan/Documents/git_repos/ABC-SBI/abcnre/src/abcnre/simulation/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabcnre\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussGaussMultiDimModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabcnre\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SummarizedStatisticalModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabcnre\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RejectionSampler, get_epsilon_quantile\n",
      "File \u001b[0;32m~/Documents/git_repos/ABC-SBI/abcnre/src/abcnre/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mABCNRE: Approximate Bayesian Computation with Neural Ratio Estimation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABCSimulator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralRatioEstimator  \n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABCSimulator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeuralRatioEstimator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# \"PosteriorValidator\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/git_repos/ABC-SBI/abcnre/src/abcnre/simulation/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mABC simulation module for ABCNRE.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mThis module provides classes and utilities for performing ABC simulation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mand generating training data for neural ratio estimation.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Main simulator class\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABCSimulator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Sampling utilities\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msamplers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RejectionSampler \u001b[38;5;66;03m#, BaseSampler\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ABCSimulator' from 'abcnre.simulation.utils' (/home/rgiordan/Documents/git_repos/ABC-SBI/abcnre/src/abcnre/simulation/utils.py)"
     ]
    }
   ],
   "source": [
    "from abcnre.simulation.models import GaussGaussMultiDimModel\n",
    "from abcnre.simulation.sampler import SummarizedStatisticalModel\n",
    "from abcnre.simulation.sampler import RejectionSampler, get_epsilon_quantile\n",
    "\n",
    "from abcnre.training import get_nn_config\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "from typing import Callable, Tuple, Any, Dict, Optional, Union\n",
    "\n",
    "key = jax.random.PRNGKey(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253daa0f-b5e3-4828-a4c7-c8f6ca26e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a model to generate draws from the first component of a 2d Gaussian\n",
    "\n",
    "model = GaussGaussMultiDimModel(mu0=0., sigma0=1.0, sigma=2.0, dim=2, n_obs=5)\n",
    "model0 = SummarizedStatisticalModel(model, lambda theta: jnp.array([ theta[0] ]))\n",
    "key, _key = jax.random.split(key, 2)\n",
    "phi_draws, x_draws = model0.sample_theta_x_multiple(_key, 5)\n",
    "phi_draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d00834-0095-4ba7-af90-d17125f178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_config = get_nn_config(network_name=\"deepset\",\n",
    "                          network_size = \"default\",\n",
    "                          training_size = \"default\",\n",
    "                          task_type = \"regressor\",\n",
    "                          lr_scheduler_name = \"reduce_on_plateau\",\n",
    "                          lr_scheduler_variant = \"default\",\n",
    "                          stopping_rules_variant = \"balanced\",\n",
    "                          experiment_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e0f85-3865-4f7b-ac80-6b5f812b116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasattr(nn_config.training, \"stopping_rules\"))\n",
    "print(isinstance(nn_config.training.stopping_rules, dict))\n",
    "print(hasattr(nn_config.training.stopping_rules, \"sample_stopping\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bf224-1f87-4cff-8f66-a45666d75171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RG: Why is it even possible for it to be both StoppingRulesConfig or Dict?\n",
    "n_samples_max = jnp.inf\n",
    "if isinstance(nn_config.training.stopping_rules, dict):\n",
    "    # Working with dictionary format - need to modify it\n",
    "    if \"sample_stopping\" not in nn_config.training.stopping_rules:\n",
    "        nn_config.training.stopping_rules[\"sample_stopping\"] = {}\n",
    "\n",
    "    nn_config.training.stopping_rules[\"sample_stopping\"][\"enabled\"] = True\n",
    "    nn_config.training.stopping_rules[\"sample_stopping\"][\n",
    "        \"max_samples\"\n",
    "    ] = n_samples_max\n",
    "elif hasattr(nn_config.training.stopping_rules, \"sample_stopping\"):\n",
    "    # Working with StoppingRulesConfig object\n",
    "    nn_config.training.stopping_rules.sample_stopping.enabled = True\n",
    "    nn_config.training.stopping_rules.sample_stopping.max_samples = (\n",
    "        n_samples_max\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1b557-8726-4b55-b6f1-cb51bb3ea9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator that matches the expected interface\n",
    "\n",
    "def get_io_generator(sample_theta_x_multiple: Callable):\n",
    "    def io_generator(key: random.PRNGKey, batch_size: int):\n",
    "        \"\"\"Adapter for the unified training interface.\"\"\"\n",
    "        phi, x = sample_theta_x_multiple(key, batch_size)\n",
    "        return {\"input\": x, \"output\": phi, \"n_simulations\": batch_size}\n",
    "    return io_generator\n",
    "\n",
    "io_generator = get_io_generator(model0.sample_theta_x_multiple)\n",
    "io_generator(key, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540a57e-e4c4-4302-b5bd-5887be91268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a nn\n",
    "from abcnre.training import train_nn\n",
    "key, train_key = random.split(key)\n",
    "summary_results = train_nn(key=train_key, config=nn_config, io_generator=io_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168f2c9-cee6-494e-95ae-05520e536c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abcnre.simulation.simulator import create_summary_stats_fn\n",
    "#abcnre/src/abcnre/simulation/simulator.py\n",
    "summary_fn = create_summary_stats_fn(\n",
    "    network=summary_results.network,\n",
    "    params=summary_results.params,\n",
    "    network_type=nn_config.network.network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230fbca-6d04-4aa2-9d58-be62c72267c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update configuration\n",
    "self.config[\"summary_stats_enabled\"] = True\n",
    "\n",
    "# Update the model if it doesn't have a summary_stat_fn or we want to override it\n",
    "if not hasattr(self.model, \"summary_stat_fn\") or override_model_summary_stats:\n",
    "    if nn_config.training.verbose:\n",
    "        print(\"Updating model's summary statistics function...\")\n",
    "    summary_fn = create_summary_stats_fn(\n",
    "        network=summary_results.network,\n",
    "        params=summary_results.params,\n",
    "        network_type=nn_config.network.network_type,\n",
    "    )\n",
    "    self.model.summary_stat_fn = summary_fn\n",
    "    self.summary_stat_fn = summary_fn\n",
    "    self._summary_params = summary_results.params\n",
    "    self._summary_config = summary_results.config\n",
    "    self._summary_network = summary_results.network\n",
    "    self._summary_training_history = summary_results.training_history\n",
    "\n",
    "    if self.observed_data is not None:\n",
    "        self.observed_summary_stats = self.summary_stat_fn(self.observed_data)\n",
    "\n",
    "# Reinitialize the sampler to use the new summary statistics function\n",
    "if self.sampler is not None:\n",
    "    self._initialize_sampler()\n",
    "\n",
    "self.trained_summary_stats = True\n",
    "\n",
    "if nn_config.training.verbose:\n",
    "    print(\"Summary statistics learned and updated successfully!\")\n",
    "    print(f\"   - Original data dimension: {self.model.data_shape}\")\n",
    "    print(f\"   - Learned summary function integrated into model\")\n",
    "\n",
    "return summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112d4fd-24d4-4257-9011-be829c06c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(nn_config.training, \"stopping_rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37747d-5090-42f3-ac8d-39b66b671321",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey_learn = jax.random.split(key)\n",
    "simulator.train_summary_network(subkey_learn, regressor_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e5fbb-874d-4764-aa68-4f5ad37546f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey_check = jax.random.split(key)\n",
    "simulator.check_summary_stats_correlation(\n",
    "    subkey_check,\n",
    "    n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f3b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efe0cdd1",
   "metadata": {},
   "source": [
    "VERIFY THE CORRELATION (CAN BE COMPUTED)\n",
    "TEST DRIVEN DEV from now on (SIMPLE TASK) SIMPLER TASK (CLASSIF REGRESSOR)\n",
    "SUMMARY LEARNER -> REGRESSOR\n",
    "FRIDAY RYAN TEST (MAKE HIS LIFE EASY AS POSSIBLE) --> 100D GAUSS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "key, key_sim = jax.random.split(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6759ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 2.1: Sample x_obs and initialize the ABCSimulator ---\")\n",
    "\n",
    "true_theta = 2.5\n",
    "key, subkey_sample = jax.random.split(key)\n",
    "x_obs = simulator.model.simulate_data(subkey_sample, true_theta)\n",
    "\n",
    "simulator.update_observed_data(x_obs)\n",
    "print(f\"Observation x_obs: {x_obs}\")\n",
    "\n",
    "quantile_distance = 1.\n",
    "key, subkey_epsilon = jax.random.split(key)\n",
    "simulator.set_epsilon_from_quantile(key = subkey_epsilon, quantile_distance=quantile_distance, n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 2.2: Save model to YAML (Optional) ---\")\n",
    "\n",
    "from abcnre.simulation import save_simulator_to_yaml\n",
    "\n",
    "\n",
    "save_simulator_to_yaml(\n",
    "    simulator,\n",
    "    results_dir / \"simulator\" / \"simulator.yaml\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 2.3 : Load model from YAML and check (Optional) ---\")\n",
    "\n",
    "from abcnre.simulation import load_simulator_from_yaml\n",
    "simulator_loaded = load_simulator_from_yaml(\n",
    "    results_dir / \"simulator\" / \"simulator.yaml\",\n",
    ")\n",
    "\n",
    "key, key_samples, key_samples_load = jax.random.split(key, 3)\n",
    "samples = simulator_loaded.generate_samples(key_samples, n_samples=100000)\n",
    "samples_load = simulator_loaded.generate_samples(key_samples_load, n_samples=100000)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.kdeplot(samples.phi.flatten(), label=\"Samples from simulator\"\n",
    "            )\n",
    "sns.kdeplot(samples_load.phi.flatten(), label=\"Samples from loaded simulator\")\n",
    "plt.legend()\n",
    "plt.title(\"Phi marginal of the two simulators\")\n",
    "plt.xlabel(\"Phi samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abcnre.training import NNConfig, NetworkConfig, TrainingConfig, get_nn_config\n",
    "print(\"--- Step 3.1: Create NNConfig for training ---\")\n",
    "nn_config = get_nn_config(network_name=\"mlp\",\n",
    "                          network_size = \"default\",\n",
    "                          training_size = \"default\",\n",
    "                          task_type = \"classifier\",\n",
    "                          lr_scheduler_name = \"reduce_on_plateau\",\n",
    "                          lr_scheduler_variant = \"default\",\n",
    "                          stopping_rules_variant = \"balanced\",\n",
    "                          experiment_name = None)\n",
    "\n",
    "\n",
    "nn_config.training.num_epochs = 500\n",
    "nn_config.training.batch_size = 1024\n",
    "nn_config.training.n_samples_per_epoch = 10240\n",
    "nn_config.training.learning_rate = 1e-2\n",
    "nn_config.training.optimizer= \"adamw\"\n",
    "nn_config.training.weight_decay = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3.2: Create NeuralRatioEstimator ---\")\n",
    "\n",
    "from abcnre.inference import NeuralRatioEstimator    \n",
    "\n",
    "estimator = NeuralRatioEstimator(\n",
    "    nn_config=nn_config,\n",
    "    simulator=simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8018464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3.3: Train the NeuralRatioEstimator ---\")\n",
    "\n",
    "key, key_train = jax.random.split(key)\n",
    "res = estimator.train(key_train, n_phi_to_store = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3.4: Save the NeuralRatioEstimator to YAML (Optional) ---\")\n",
    "\n",
    "from abcnre.inference.io import save_estimator_to_yaml\n",
    "save_estimator_to_yaml(\n",
    "    estimator,\n",
    "    results_dir / \"estimator\" / \"estimator.yaml\",\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deab27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3.5: Load the NeuralRatioEstimator from YAML and check (Optional) ---\")\n",
    "\n",
    "from abcnre.inference import load_estimator_from_yaml\n",
    "\n",
    "estimator_loaded = load_estimator_from_yaml(\n",
    "    results_dir / \"estimator\" / \"estimator.yaml\",\n",
    ")\n",
    "\n",
    "key, key_samples_estimator, key_samples_estimator_load = jax.random.split(key, 3)\n",
    "samples_estimator = estimator.simulator.generate_samples(key_samples_estimator, n_samples=100000)\n",
    "samples_estimator_load = estimator_loaded.simulator.generate_samples(key_samples_estimator_load, n_samples=100000)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.kdeplot(samples_estimator.phi.flatten(), label=\"Samples from estimator\")\n",
    "sns.kdeplot(samples_estimator_load.phi.flatten(), label=\"Samples from loaded estimator\")\n",
    "plt.legend()\n",
    "plt.title(\"Phi marginal of the two estimators\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABC-SBI-kernel",
   "language": "python",
   "name": "abc-sbi-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
