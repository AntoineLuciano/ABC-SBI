{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path: /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss\n",
      "New path: /Users/antoineluciano/Documents/Recherche/ABC-SBI\n"
     ]
    }
   ],
   "source": [
    "from jax import random, jit, vmap\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print(\"Old path:\", path)\n",
    "path = (path.split('/'))\n",
    "path = path[:path.index(\"ABC-SBI\")+1]\n",
    "path = '/'.join(path)\n",
    "print(\"New path:\", path)\n",
    "os.chdir(path)\n",
    "from functions.simulation import get_dataset, get_epsilon_star, get_newdataset\n",
    "from functions.training import train_loop\n",
    "from functions.SBC import SBC_epsilon, plot_SBC\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import pickle \n",
    "import lzma\n",
    "from jax.scipy.stats import norm\n",
    "\n",
    "\n",
    "@jit\n",
    "def prior_simulator(key):\n",
    "    return random.normal(key, (1,))*SIGMA0 + MU0\n",
    "\n",
    "@jit\n",
    "def data_simulator(key, theta):\n",
    "    return (random.normal(key, (N_DATA,))*SIGMA + theta).astype(float)\n",
    "\n",
    "@jit\n",
    "def discrepancy(y, y_true):\n",
    "    return (jnp.mean(y) - jnp.mean(y_true))**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 10.0, TRUE_MU = 1.0, ACCEPT_RATE = 1.0\n",
      "--------------------\n",
      "\n",
      "\n",
      "Selection of epsilon star...\n",
      "Distances: min =  3.2896725e-08 max =  1381.2203 mean =  101.74406 std =  141.39943\n",
      "Time to select epsilon star: 0.64s\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Time to simulate the testing dataset: 0.90s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 50.34%, Initial test accuracy: 50.34%\n",
      "Training for 100 epochs...\n",
      "Epoch 1/100, mean train accuracy: 90.42%, mean test accuracy: 97.35%, lr scale: 1.0 in 8.64 sec\n",
      "Epoch 2/100, mean train accuracy: 95.11%, mean test accuracy: 97.47%, lr scale: 1.0 in 7.88 sec\n",
      "Epoch 3/100, mean train accuracy: 95.80%, mean test accuracy: 94.71%, lr scale: 1.0 in 8.18 sec\n",
      "Epoch 4/100, mean train accuracy: 96.12%, mean test accuracy: 96.20%, lr scale: 1.0 in 7.93 sec\n",
      "Epoch 5/100, mean train accuracy: 97.30%, mean test accuracy: 98.26%, lr scale: 0.5 in 7.91 sec\n",
      "Epoch 6/100, mean train accuracy: 97.45%, mean test accuracy: 98.08%, lr scale: 0.5 in 8.25 sec\n",
      "Epoch 7/100, mean train accuracy: 97.84%, mean test accuracy: 98.35%, lr scale: 0.5 in 8.07 sec\n",
      "Epoch 8/100, mean train accuracy: 97.84%, mean test accuracy: 98.59%, lr scale: 0.5 in 7.99 sec\n",
      "Epoch 9/100, mean train accuracy: 98.22%, mean test accuracy: 98.48%, lr scale: 0.5 in 7.91 sec\n",
      "Epoch 10/100, mean train accuracy: 98.02%, mean test accuracy: 98.52%, lr scale: 0.5 in 7.94 sec\n",
      "Epoch 11/100, mean train accuracy: 98.33%, mean test accuracy: 98.74%, lr scale: 0.25 in 7.86 sec\n",
      "Epoch 12/100, mean train accuracy: 98.66%, mean test accuracy: 98.51%, lr scale: 0.25 in 7.98 sec\n",
      "Epoch 13/100, mean train accuracy: 98.39%, mean test accuracy: 98.71%, lr scale: 0.125 in 8.00 sec\n",
      "Epoch 14/100, mean train accuracy: 98.77%, mean test accuracy: 98.81%, lr scale: 0.125 in 7.93 sec\n",
      "Epoch 15/100, mean train accuracy: 98.69%, mean test accuracy: 98.64%, lr scale: 0.125 in 7.85 sec\n",
      "Epoch 16/100, mean train accuracy: 98.79%, mean test accuracy: 98.86%, lr scale: 0.0625 in 7.87 sec\n",
      "Epoch 17/100, mean train accuracy: 98.83%, mean test accuracy: 98.84%, lr scale: 0.0625 in 7.94 sec\n",
      "Epoch 18/100, mean train accuracy: 98.82%, mean test accuracy: 98.92%, lr scale: 0.03125 in 8.09 sec\n",
      "Epoch 19/100, mean train accuracy: 98.88%, mean test accuracy: 98.92%, lr scale: 0.03125 in 7.81 sec\n",
      "Epoch 20/100, mean train accuracy: 98.86%, mean test accuracy: 98.91%, lr scale: 0.015625 in 8.00 sec\n",
      "Epoch 21/100, mean train accuracy: 98.88%, mean test accuracy: 98.93%, lr scale: 0.015625 in 7.91 sec\n",
      "Epoch 22/100, mean train accuracy: 98.93%, mean test accuracy: 98.93%, lr scale: 0.015625 in 8.02 sec\n",
      "Epoch 23/100, mean train accuracy: 98.92%, mean test accuracy: 98.94%, lr scale: 0.0078125 in 8.17 sec\n",
      "Epoch 24/100, mean train accuracy: 98.93%, mean test accuracy: 98.91%, lr scale: 0.0078125 in 8.04 sec\n",
      "Epoch 25/100, mean train accuracy: 98.95%, mean test accuracy: 98.95%, lr scale: 0.00390625 in 7.89 sec\n",
      "Epoch 26/100, mean train accuracy: 98.92%, mean test accuracy: 98.95%, lr scale: 0.001953125 in 7.88 sec\n",
      "Epoch 27/100, mean train accuracy: 98.93%, mean test accuracy: 98.95%, lr scale: 0.001953125 in 7.93 sec\n",
      "Epoch 28/100, mean train accuracy: 98.94%, mean test accuracy: 98.95%, lr scale: 0.0009765625 in 7.88 sec\n",
      "Learning rate reached 1.00E-06, stopping training\n",
      "Time to train the neural network: 235.85s\n",
      "\n",
      "Simulation Based Calibration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dac14b8b6d341a5bcbd2eb30c687bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    " \n",
    "MU0 = 0.\n",
    "SIGMA = 1.\n",
    "MODEL_ARGS = [SIGMA]\n",
    "N_DATA = 100\n",
    "N_POINTS_TRAIN = 1000000\n",
    "N_POINTS_TEST = 100000\n",
    "N_POINTS_EPS = 10000\n",
    "sim_args = None\n",
    "\n",
    "\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 7\n",
    "COOLDOWN = 0\n",
    "FACTOR = .5\n",
    "RTOL = 1e-4  \n",
    "ACCUMULATION_SIZE = 200\n",
    "LEARNING_RATE_MIN = 1e-6\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_BATCH = 1024\n",
    "NUM_CLASSES = 2\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 7\n",
    "WDECAY = .001\n",
    "N_GRID_FINAL = 10000\n",
    "N_GRID_EXPLO = 1000\n",
    "MINN, MAXX = -50.,50. \n",
    "L = 127\n",
    "N_SBC = (L+1)*100\n",
    "\n",
    "PATH_RESULTS = os.getcwd() + \"/examples/Gauss-Gauss/results/\"\n",
    "\n",
    "\n",
    "\n",
    "SIGMAS0 = [10*SIGMA]\n",
    "\n",
    "for SIGMA0 in SIGMAS0:\n",
    "    TRUE_MUS = [.1*SIGMA0, .5*SIGMA0, SIGMA0, 1.5*SIGMA0]\n",
    "    PRIOR_ARGS = [MU0, SIGMA0]\n",
    "    PRIOR_LOGPDF = lambda x: norm.logpdf(x, loc = MU0, scale = SIGMA0)\n",
    "\n",
    "    for TRUE_MU in TRUE_MUS:\n",
    "        EPSILON_STAR = jnp.inf\n",
    "        key, subkey = random.split(key)\n",
    "        TRUE_DATA = data_simulator(subkey, TRUE_MU)\n",
    "        for ACCEPT_RATE in [1., .999, .99, .975, .95, .925]:\n",
    "            print(\"\\n\\n--------------------\")\n",
    "            print(\"SIGMA0 = {}, TRUE_MU = {}, ACCEPT_RATE = {}\".format(SIGMA0, TRUE_MU, ACCEPT_RATE))\n",
    "            print(\"--------------------\\n\\n\")\n",
    "                    \n",
    "            \n",
    "            time_eps = time.time()\n",
    "            print(\"Selection of epsilon star...\")\n",
    "            EPSILON_STAR, key = get_epsilon_star(key, ACCEPT_RATE, N_POINTS_EPS, prior_simulator, data_simulator, discrepancy, TRUE_DATA, quantile_rate = .99, epsilon = EPSILON_STAR)\n",
    "            print('Time to select epsilon star: {:.2f}s\\n'.format(time.time()-time_eps))\n",
    "\n",
    "            print(\"Simulations of the testing dataset...\")\n",
    "            time_sim = time.time()\n",
    "            X_test, y_test, key = get_newdataset(key, N_POINTS_TEST, prior_simulator, data_simulator, discrepancy, EPSILON_STAR, TRUE_DATA)\n",
    "            print('Time to simulate the testing dataset: {:.2f}s\\n'.format(time.time()-time_sim))\n",
    "\n",
    "            # print(\"Simulations of the training dataset...\")\n",
    "            # time_sim = time.time()\n",
    "            # X_train, y_train, key = get_dataset(key, N_POINTS_TRAIN, prior_simulator, data_simulator, discrepancy, EPSILON_STAR, TRUE_DATA)\n",
    "            # print('Time to simulate the training dataset: {:.2f}s\\n'.format(time.time()-time_sim))\n",
    "\n",
    "\n",
    "            print(\"Training the neural network...\")\n",
    "            time_nn = time.time()\n",
    "            params, train_accuracy, train_losses, test_accuracy, test_losses, key = train_loop(key, N_EPOCHS, NUM_LAYERS, HIDDEN_SIZE, NUM_CLASSES, BATCH_SIZE, NUM_BATCH, LEARNING_RATE, WDECAY, PATIENCE, COOLDOWN, FACTOR, RTOL, ACCUMULATION_SIZE, LEARNING_RATE_MIN, prior_simulator, data_simulator, discrepancy, true_data = TRUE_DATA, X_train = None, y_train = None, X_test = X_test, y_test =  y_test, N_POINTS_TRAIN = N_POINTS_TRAIN, N_POINTS_TEST = N_POINTS_TEST, epsilon = EPSILON_STAR, verbose = True)\n",
    "            print('Time to train the neural network: {:.2f}s\\n'.format(time.time()-time_nn))\n",
    "\n",
    "\n",
    "            print(\"Simulation Based Calibration...\")\n",
    "            time_sbc = time.time()\n",
    "\n",
    "            ranks, thetas_tilde, thetas, key = SBC_epsilon(key = key, N_SBC = N_SBC, L = L, params = params, epsilon = EPSILON_STAR, true_data = TRUE_DATA, prior_simulator = prior_simulator, prior_logpdf = PRIOR_LOGPDF, data_simulator = data_simulator, discrepancy = discrepancy, n_grid_explo = N_GRID_EXPLO, n_grid_final = N_GRID_FINAL, minn = MINN, maxx = MAXX)\n",
    "\n",
    "            print('Time to perform SBC: {:.2f}s\\n'.format(time.time()-time_sbc))\n",
    "\n",
    "\n",
    "            pickle_dico = {\"ranks\": ranks, \"thetas_tilde\": thetas_tilde, \"thetas\": thetas, \"epsilon\":EPSILON_STAR, \"KEY\":key, \"N_SBC\":N_SBC, \"L\":L, \"N_GRID_EXPLO\": N_GRID_EXPLO, 'N_GRID_FINAL': N_GRID_FINAL,\"TRUE_DATA\": TRUE_DATA, \"TRUE_THETA\": TRUE_MU, \"params\": params, \"train_accuracy\":train_accuracy, \"test_accuracy\":test_accuracy, \"MODEL_ARGS\":MODEL_ARGS, \"PRIOR_ARGS\":PRIOR_ARGS, \"N_POINTS_TRAIN\":N_POINTS_TRAIN, \"N_POINTS_TEST\":N_POINTS_TEST, \"N_DATA\":N_DATA, \"N_EPOCHS\":N_EPOCHS, \"LEARNING_RATE\":LEARNING_RATE, \"PATIENCE\":PATIENCE, \"COOLDOWN\":COOLDOWN, \"FACTOR\":FACTOR, \"RTOL\":RTOL, \"ACCUMULATION_SIZE\":ACCUMULATION_SIZE, \"LEARNING_RATE_MIN\":LEARNING_RATE_MIN, \"BATCH_SIZE\":BATCH_SIZE, \"NUM_BATCH\":NUM_BATCH, \"NUM_CLASSES\":NUM_CLASSES, \"HIDDEN_SIZE\":HIDDEN_SIZE, \"NUM_LAYERS\":NUM_LAYERS, \"WDECAY\":WDECAY}\n",
    "\n",
    "            NAMEFILE = PATH_RESULTS+\"GaussGauss_sigma_{}_sigma0_{}_mu_{}_acc_{:.3}_eps_{:.5}\"\n",
    "            with lzma.open(NAMEFILE+\".xy\", \"wb\") as f:\n",
    "                pickle.dump(pickle_dico, f)\n",
    "            print(\"Data saved in \", NAMEFILE+\".xy\")\n",
    "\n",
    "            title = \"Normal w/ known std\\nsigma = {}, sigma0 = {} mu = {}\\nalpha = {:.2%}, eps = {:.3} accuracy = {:.2%}\".format(SIGMA, SIGMA0, TRUE_MU, ACCEPT_RATE, EPSILON_STAR, test_accuracy[-1])\n",
    "\n",
    "            plot_SBC(ranks, L, B = 16, title = title, save_name = NAMEFILE+\".png\")\n",
    "            print(\"Plot saved in \",NAMEFILE+\".png\")\n",
    "            \n",
    "            print(\"\\n\\n--------------------\")\n",
    "            print(\"ITERATION (ACC = {}) DONE IN {} SECONDS!\".format(ACCEPT_RATE, time.time()-time_eps))\n",
    "            print(\"--------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
