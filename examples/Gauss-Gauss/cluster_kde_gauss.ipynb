{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path: /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss\n",
      "New path: /Users/antoineluciano/Documents/Recherche/ABC-SBI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoineluciano/.pyenv/versions/3.10.13/envs/jax_env/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from jax import random, jit, vmap\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print(\"Old path:\", path)\n",
    "path = (path.split('/'))\n",
    "path = path[:path.index(\"ABC-SBI\")+1]\n",
    "path = '/'.join(path)\n",
    "print(\"New path:\", path)\n",
    "os.chdir(path)\n",
    "\n",
    "from functions.SBC import logratio_z, logratio_batch_z, post_pdf_z, find_grid_explorative\n",
    "# from functions.simulation import get_dataset, ABC_epsilon, get_epsilon_star\n",
    "from functions.training import train_loop\n",
    "from functions.SBC import SBC_epsilon, plot_SBC, find_grid_explorative, post_pdf_z, post_sample, new_post_pdf_z\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import pickle \n",
    "import lzma\n",
    "from jax.scipy.stats import norm, gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sbibm.metrics import c2st\n",
    "import torch\n",
    "\n",
    "\n",
    "@jit\n",
    "def prior_simulator(key):\n",
    "    return random.normal(key, (1,))*SIGMA0 + MU0\n",
    "\n",
    "@jit\n",
    "def data_simulator(key, theta):\n",
    "    return (random.normal(key, (N_DATA,))*SIGMA + theta).astype(float)\n",
    "\n",
    "@jit\n",
    "def discrepancy(y, y_true):\n",
    "    return (jnp.mean(y) - jnp.mean(y_true))**2\n",
    "\n",
    "def true_post(z):\n",
    "    mu_post = (MU0*SIGMA**2 + SIGMA0**2 * np.sum(z))/(SIGMA0**2*len(z) + SIGMA**2)\n",
    "    sigma2_post = 1/(1/SIGMA0**2 + len(z)/SIGMA**2)\n",
    "    return stats.norm(loc = mu_post, scale = np.sqrt(sigma2_post))\n",
    "\n",
    "\n",
    "def true_post(z):\n",
    "    mu_post = (MU0*SIGMA**2 + SIGMA0**2 * np.sum(z))/(SIGMA0**2*len(z) + SIGMA**2)\n",
    "    sigma2_post = 1/(1/SIGMA0**2 + len(z)/SIGMA**2)\n",
    "    return stats.norm(loc = mu_post, scale = np.sqrt(sigma2_post))\n",
    "\n",
    "def true_ratio_z(mus, z, prior, posterior):\n",
    "    return posterior(z).pdf(mus)/prior.pdf(mus)\n",
    "\n",
    "def true_decision_z(mus, z, prior, posterior):\n",
    "    return 1/(1+1/true_ratio_z(mus, z, prior, posterior))\n",
    "\n",
    "def true_pseudo_ratio_z(mus, z, bar_xobs, epsilon, prior, posterior):\n",
    "    pseudo = true_pseudo_post(mus, bar_xobs, epsilon, prior)\n",
    "    Z_pseudo = np.trapz(pseudo, mus)\n",
    "    return posterior(z).pdf(mus)/pseudo*Z_pseudo\n",
    "\n",
    "def true_pseudo_decision_z(mus, z, bar_xobs, epsilon, prior, posterior):\n",
    "    return 1/(1+1/true_pseudo_ratio_z(mus, z, bar_xobs, epsilon, prior, posterior))\n",
    "\n",
    "def true_pseudo_post(mus, bar_xobs, epsilon, prior):\n",
    "    return prior.pdf(mus)*(norm.cdf(bar_xobs+np.sqrt(epsilon), loc = mus, scale = SIGMA/np.sqrt(N_DATA)) - norm.cdf(bar_xobs-np.sqrt(epsilon), loc = mus, scale = SIGMA/np.sqrt(N_DATA)))\n",
    "\n",
    "def true_pseudo_decision_z(mus, z, bar_xobs, epsilon, prior, posterior):\n",
    "    return 1/(1+1/true_pseudo_ratio_z(mus, z, bar_xobs, epsilon, prior, posterior))\n",
    "\n",
    "def decision_z(params, mus, z):\n",
    "    return 1/(1+jnp.exp(-logratio_z(params, mus, z)))\n",
    "def decision_batch_z(params, mus, z):\n",
    "    return 1/(1+jnp.exp(-logratio_batch_z(params, mus, z)))\n",
    "\n",
    "def ABC_gauss_single(key, true_data, epsilon):\n",
    "    key, key_xbar = random.split(key)\n",
    "    xbar = random.truncated_normal(key_xbar, lower = (jnp.mean(true_data)-jnp.sqrt(epsilon)-MU0)/jnp.sqrt(SIGMA0**2+SIGMA**2/len(true_data)), upper = (jnp.mean(true_data)+jnp.sqrt(epsilon)-MU0)/jnp.sqrt(SIGMA0**2+SIGMA**2/len(true_data)))*jnp.sqrt(SIGMA0**2+SIGMA**2/len(true_data)) + MU0\n",
    "    dist = (jnp.mean(true_data)-xbar)**2\n",
    "    key, key_z = random.split(key)\n",
    "    z = random.normal(key_z, (len(true_data),))*SIGMA\n",
    "    z = z-jnp.mean(z)+xbar\n",
    "    key, key_mu = random.split(key)\n",
    "    mu = random.normal(key_mu, (1,))*SIGMA/jnp.sqrt(len(true_data)) + xbar\n",
    "    return z, mu, dist\n",
    "\n",
    "\n",
    "def ABC_gauss(key, true_data, epsilon, N_ABC):\n",
    "    keys = random.split(key, N_ABC+1)\n",
    "    zs, mus, dists = vmap(jit(ABC_gauss_single), (0, None, None))(keys[1:], true_data, epsilon)\n",
    "    return zs, mus, dists, keys[0]\n",
    "\n",
    "def get_epsilon_star_gauss(key, acceptance_rate, n_points, prior_simulator, data_simulator, discrepancy, true_data, quantile_rate = .9, epsilon = jnp.inf, return_accept = False):\n",
    "    new_epsilon = epsilon\n",
    "    accept = 1.\n",
    "    \n",
    "    datas, thetas, dists, key = ABC_gauss(key, true_data, epsilon, n_points)\n",
    "    if epsilon == jnp.inf:\n",
    "        print(\"Distances: min = \", jnp.min(dists), \"max = \", jnp.max(dists), \"mean = \", jnp.mean(dists), \"std = \", jnp.std(dists))\n",
    "    while accept > acceptance_rate:\n",
    "        epsilon = new_epsilon\n",
    "        new_epsilon = float(jnp.quantile(dists, quantile_rate))\n",
    "        datas, thetas, dists, key = ABC_gauss(key, true_data, new_epsilon, n_points)\n",
    "        key, subkey = random.split(key)\n",
    "        keys_pred = random.split(subkey, n_points)\n",
    "        datas_pred = vmap(data_simulator, in_axes=(0, 0))(keys_pred, thetas)\n",
    "        new_dists = vmap(discrepancy, in_axes=(0, None))(datas_pred, true_data)\n",
    "        accept = jnp.mean(new_dists < new_epsilon)\n",
    "        epsilon = new_epsilon\n",
    "        print(\"epsilon: \", epsilon, \"acceptance rate: \", accept)\n",
    "    if return_accept: \n",
    "        return epsilon, accept, key\n",
    "    return epsilon, key\n",
    "\n",
    "def get_dataset_gauss(key, n_points, prior_simulator, data_simulator, discrepancy, epsilon, true_data):\n",
    "    n_points = n_points//2\n",
    "    zs0, thetas0, _, key = ABC_gauss(key, true_data, epsilon, n_points)\n",
    "    _, thetas1, _, key = ABC_gauss(key, true_data, epsilon, n_points)    \n",
    "    zs = jnp.concatenate([zs0, zs0], axis=0)\n",
    "    thetas = jnp.concatenate([thetas0, thetas1], axis=0)\n",
    "    ys = jnp.append(jnp.zeros(n_points), jnp.ones(n_points)).astype(int)\n",
    "    Xs = jnp.concatenate([thetas, zs], axis=1)\n",
    "    return Xs, ys, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 1.0\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.01s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 50.10%, Initial test accuracy: 51.46%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 60.25%, mean test accuracy: 72.17%, lr scale: 1.0 in 0.82 sec\n",
      "Epoch 2/2, mean train accuracy: 67.97%, mean test accuracy: 83.98%, lr scale: 1.0 in 0.04 sec\n",
      "Time to train the neural network: 1.10s\n",
      "\n",
      "C2ST accuracy:  tensor([0.9308])\n",
      "Data saved in  /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss/results_for_paper/N_data_5/sigma0_5/1_mu_1.5e+01/GaussGauss_ndata_5_sigma0_5_mu_15.0_alpha_1.0_eps_999.95.xy\n",
      "\n",
      "\n",
      "--------------------\n",
      "ITERATION (ALPHA = 1.0) DONE IN 5.839378833770752 SECONDS!\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 0.99\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.01s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 41.31%, Initial test accuracy: 41.80%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 54.39%, mean test accuracy: 63.09%, lr scale: 1.0 in 0.59 sec\n",
      "Epoch 2/2, mean train accuracy: 77.93%, mean test accuracy: 82.81%, lr scale: 1.0 in 0.06 sec\n",
      "Time to train the neural network: 0.92s\n",
      "\n",
      "C2ST accuracy:  tensor([0.9895])\n",
      "Data saved in  /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss/results_for_paper/N_data_5/sigma0_5/1_mu_1.5e+01/GaussGauss_ndata_5_sigma0_5_mu_15.0_alpha_0.99_eps_693.9.xy\n",
      "\n",
      "\n",
      "--------------------\n",
      "ITERATION (ALPHA = 0.99) DONE IN 4.977397918701172 SECONDS!\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 0.9\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.01s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 51.46%, Initial test accuracy: 50.00%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 59.96%, mean test accuracy: 71.68%, lr scale: 1.0 in 0.78 sec\n",
      "Epoch 2/2, mean train accuracy: 77.34%, mean test accuracy: 82.62%, lr scale: 1.0 in 0.05 sec\n",
      "Time to train the neural network: 1.12s\n",
      "\n",
      "C2ST accuracy:  tensor([0.9105])\n",
      "Data saved in  /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss/results_for_paper/N_data_5/sigma0_5/1_mu_1.5e+01/GaussGauss_ndata_5_sigma0_5_mu_15.0_alpha_0.9_eps_448.31.xy\n",
      "\n",
      "\n",
      "--------------------\n",
      "ITERATION (ALPHA = 0.9) DONE IN 5.363661050796509 SECONDS!\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 0.5\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.00s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 53.03%, Initial test accuracy: 52.93%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 50.88%, mean test accuracy: 77.93%, lr scale: 1.0 in 1.17 sec\n",
      "Epoch 2/2, mean train accuracy: 75.20%, mean test accuracy: 82.32%, lr scale: 1.0 in 0.09 sec\n",
      "Time to train the neural network: 1.51s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoineluciano/.pyenv/versions/3.10.13/envs/jax_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2ST accuracy:  tensor([0.8619])\n",
      "Data saved in  /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss/results_for_paper/N_data_5/sigma0_5/1_mu_1.5e+01/GaussGauss_ndata_5_sigma0_5_mu_15.0_alpha_0.5_eps_217.36.xy\n",
      "\n",
      "\n",
      "--------------------\n",
      "ITERATION (ALPHA = 0.5) DONE IN 5.794081926345825 SECONDS!\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 0.1\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.00s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 50.00%, Initial test accuracy: 50.00%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 49.61%, mean test accuracy: 50.00%, lr scale: 1.0 in 0.82 sec\n",
      "Epoch 2/2, mean train accuracy: 49.02%, mean test accuracy: 50.00%, lr scale: 1.0 in 0.07 sec\n",
      "Time to train the neural network: 1.18s\n",
      "\n",
      "C2ST accuracy:  tensor([0.9837])\n",
      "Data saved in  /Users/antoineluciano/Documents/Recherche/ABC-SBI/examples/Gauss-Gauss/results_for_paper/N_data_5/sigma0_5/1_mu_1.5e+01/GaussGauss_ndata_5_sigma0_5_mu_15.0_alpha_0.1_eps_69.175.xy\n",
      "\n",
      "\n",
      "--------------------\n",
      "ITERATION (ALPHA = 0.1) DONE IN 5.478837013244629 SECONDS!\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "SIGMA0 = 5.0, TRUE_MU = 15.0, ALPHA = 0.01\n",
      "--------------------\n",
      "\n",
      "\n",
      "Simulations of the testing dataset...\n",
      "Test check: True\n",
      "Time to simulate the testing dataset: 0.00s\n",
      "\n",
      "Simulations of the training dataset...\n",
      "Train check: True\n",
      "Time to simulate the training dataset: 0.00s\n",
      "\n",
      "Training the neural network...\n",
      "Initial accuracy: 50.00%, Initial test accuracy: 50.00%\n",
      "Training for 2 epochs...\n",
      "Epoch 1/2, mean train accuracy: 49.41%, mean test accuracy: 50.00%, lr scale: 1.0 in 0.53 sec\n",
      "Epoch 2/2, mean train accuracy: 52.73%, mean test accuracy: 50.00%, lr scale: 1.0 in 0.04 sec\n",
      "Time to train the neural network: 0.72s\n",
      "\n",
      "C2ST accuracy:  tensor([0.8770])\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    " \n",
    "MU0 = 0.\n",
    "SIGMA = 1.\n",
    "MODEL_ARGS = [SIGMA]\n",
    "\n",
    "N_POINTS_TRAIN = 1025\n",
    "N_POINTS_TEST = 1024\n",
    "N_POINTS_EPS = 10000\n",
    "N_MUS = 1\n",
    "N_C2ST = 10000\n",
    "sim_args = None\n",
    "\n",
    "\n",
    "N_EPOCHS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 7\n",
    "COOLDOWN = 0\n",
    "FACTOR = .5\n",
    "RTOL = 1e-4  \n",
    "ACCUMULATION_SIZE = 200\n",
    "LEARNING_RATE_MIN = 1e-6\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_BATCH = 1024\n",
    "NUM_CLASSES = 2\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 7\n",
    "WDECAY = .001\n",
    "N_GRID_FINAL = 10000\n",
    "N_GRID_EXPLO = 1000\n",
    "\n",
    "\n",
    "PATH_RESULTS = os.getcwd() + \"/examples/Gauss-Gauss/results_for_paper/\"\n",
    "if not os.path.exists(PATH_RESULTS):\n",
    "    os.makedirs(PATH_RESULTS)\n",
    "    \n",
    "\n",
    "N_DATAS = [5, 10, 50, 100]\n",
    "SIGMAS0 = [5*SIGMA, 10*SIGMA, 20*SIGMA]\n",
    "ALPHAS = [1., .99, .9,  .5, .1, .01, .001]\n",
    "\n",
    "\n",
    "for N_DATA in N_DATAS:\n",
    "    PATH_N_DATA = PATH_RESULTS+ \"N_data_{}/\".format(N_DATA)\n",
    "    if not os.path.exists(PATH_N_DATA):\n",
    "        os.makedirs(PATH_N_DATA)\n",
    "\n",
    "    \n",
    "    for SIGMA0 in SIGMAS0:\n",
    "        PATH_SIGMA0 = PATH_N_DATA+ \"sigma0_{}/\".format(int(SIGMA0))\n",
    "        if not os.path.exists(PATH_SIGMA0):\n",
    "            os.makedirs(PATH_SIGMA0)\n",
    "        \n",
    "        PRIOR_ARGS = [MU0, SIGMA0]\n",
    "        PRIOR_LOGPDF = lambda x: norm.logpdf(x, loc = MU0, scale = SIGMA0)\n",
    "        prior = stats.norm(loc = MU0, scale = SIGMA0)\n",
    "        TRUE_MUS = np.append(np.sort(stats.norm.rvs(size = N_MUS-1, random_state = 0)*SIGMA0), 3*SIGMA0)\n",
    "\n",
    "        MINN, MAXX = prior.interval(1-1e-5)\n",
    "        dico_sigma0 = {\"SIGMA0\": SIGMA0, \"TRUE_MUS\": TRUE_MUS, \"N_DATA\":N_DATA}\n",
    "        TRUE_DATAS = {}\n",
    "        PARAMS_SIGMA0 = {}\n",
    "        TEST_ACCURACY_SIGMA0 = {}\n",
    "        EPSILONS_SIGMA0 = {}\n",
    "        C2ST_ACCURACY_SIGMA0 = {}\n",
    "        for i,TRUE_MU in enumerate(TRUE_MUS):\n",
    "            i = i+1\n",
    "            PATH_TRUE_MU = PATH_SIGMA0 + \"{}_mu_{:.2}/\".format(i, TRUE_MU)\n",
    "            if not os.path.exists(PATH_TRUE_MU):\n",
    "                os.makedirs(PATH_TRUE_MU)\n",
    "            key, subkey = random.split(key)\n",
    "            TRUE_DATA = data_simulator(subkey, TRUE_MU)\n",
    "            TRUE_DATAS[i] = TRUE_DATA\n",
    "            zs, mus, dists, key = ABC_gauss(key, TRUE_DATA, 1000, 1000000)\n",
    "            EPSILONS = {1.: jnp.inf}\n",
    "            PARAMS = {}\n",
    "            TEST_ACCURACY = {}\n",
    "            C2ST_ACCURACY = {}\n",
    "            true_sample = true_post(TRUE_DATA).rvs(N_C2ST)\n",
    "        \n",
    "            for alpha in ALPHAS: \n",
    "                EPSILONS[alpha] = jnp.quantile(dists, alpha)\n",
    "            dico_mu = {\"TRUE_MU\":TRUE_MU, \"TRUE_DATA\":TRUE_DATA, \"N_DATA\":N_DATA, \"SIGMA0\":SIGMA0, \"EPSILONS\":EPSILONS, \"ALPHAS\":ALPHAS}\n",
    "            for ALPHA in ALPHAS:\n",
    "                time_iter = time.time()\n",
    "                EPSILON = EPSILONS[ALPHA]\n",
    "                print(\"\\n\\n--------------------\")\n",
    "                print(\"SIGMA0 = {}, TRUE_MU = {}, ALPHA = {}\".format(SIGMA0, TRUE_MU, ALPHA))\n",
    "                print(\"--------------------\\n\\n\")\n",
    "                        \n",
    "                print(\"Simulations of the testing dataset...\")\n",
    "                time_sim = time.time()\n",
    "                key, subkey = random.split(key)\n",
    "                X_test, y_test, key = get_dataset_gauss(subkey, N_POINTS_TEST, prior_simulator, data_simulator, discrepancy, EPSILON, TRUE_DATA)\n",
    "                print(\"Test check:\", np.any(X_test[:,0]!=np.sort(X_test[:,0])))\n",
    "                print('Time to simulate the testing dataset: {:.2f}s\\n'.format(time.time()-time_sim))\n",
    "\n",
    "\n",
    "                print(\"Simulations of the training dataset...\")\n",
    "                time_sim = time.time()\n",
    "                key, subkey = random.split(key)\n",
    "                X_train, y_train, key = get_dataset_gauss(subkey, N_POINTS_TRAIN, prior_simulator, data_simulator, discrepancy, EPSILON, TRUE_DATA)\n",
    "                print(\"Train check:\", np.any(X_train[:,0]!=np.sort(X_train[:,0])))\n",
    "                print('Time to simulate the training dataset: {:.2f}s\\n'.format(time.time()-time_sim))\n",
    "                \n",
    "                print(\"Training the neural network...\")\n",
    "                time_nn = time.time()\n",
    "                params, train_accuracy, train_losses, test_accuracy, test_losses, key = train_loop(key, N_EPOCHS, NUM_LAYERS, HIDDEN_SIZE, NUM_CLASSES, BATCH_SIZE, NUM_BATCH, LEARNING_RATE, WDECAY, PATIENCE, COOLDOWN, FACTOR, RTOL, ACCUMULATION_SIZE, LEARNING_RATE_MIN, prior_simulator, data_simulator, discrepancy, true_data = TRUE_DATA, X_train = X_train, y_train = y_train, X_test = X_test, y_test =  y_test, N_POINTS_TRAIN = N_POINTS_TRAIN, N_POINTS_TEST = N_POINTS_TEST, epsilon = EPSILON, verbose = True)\n",
    "                print('Time to train the neural network: {:.2f}s\\n'.format(time.time()-time_nn))\n",
    "                \n",
    "                kde_approx = gaussian_kde(X_train[:,0], bw_method = \"scott\")\n",
    "\n",
    "                grid_kde_nn, pdf_kde_nn = find_grid_explorative(lambda x: new_post_pdf_z(params, x, TRUE_DATA, kde_approx), N_GRID_EXPLO, N_GRID_FINAL, MINN, MAXX)\n",
    "                key, subkey = random.split(key)\n",
    "                sample_kde_nn = post_sample(subkey, grid_kde_nn, pdf_kde_nn, N_C2ST)\n",
    "                \n",
    "                accuracy_c2st = c2st(torch.tensor(true_sample[:,None]), torch.tensor(sample_kde_nn[:,None]))\n",
    "                print(\"C2ST accuracy: \", np.array(accuracy_c2st)[0])\n",
    "                \n",
    "\n",
    "                PARAMS[alpha] = params\n",
    "                TEST_ACCURACY[alpha] = test_accuracy[-1]\n",
    "                C2ST_ACCURACY[alpha] = np.array(accuracy_c2st)[0]\n",
    "                \n",
    "\n",
    "                # print(\"Simulation Based Calibration...\")\n",
    "                # time_sbc = time.time()\n",
    "\n",
    "                # ranks, thetas_tilde, thetas, key = SBC_epsilon(key = key, N_SBC = N_SBC, L = L, params = params, epsilon = EPSILON_STAR, true_data = TRUE_DATA, prior_simulator = prior_simulator, prior_logpdf = PRIOR_LOGPDF, data_simulator = data_simulator, discrepancy = discrepancy, n_grid_explo = N_GRID_EXPLO, n_grid_final = N_GRID_FINAL, minn = MINN, maxx = MAXX)\n",
    "\n",
    "                # print('Time to perform SBC: {:.2f}s\\n'.format(time.time()-time_sbc))\n",
    "\n",
    "\n",
    "                pickle_dico = {\"ACCEPT_RATE\":ALPHA, \"epsilon\":EPSILON, \"KEY\":key, \"TRUE_DATA\": TRUE_DATA, \"TRUE_THETA\": TRUE_MU, \"params\": params, \"train_accuracy\":train_accuracy, \"test_accuracy\":test_accuracy, \"MODEL_ARGS\":MODEL_ARGS, \"PRIOR_ARGS\":PRIOR_ARGS, \"N_POINTS_TRAIN\":N_POINTS_TRAIN, \"N_POINTS_TEST\":N_POINTS_TEST, \"N_DATA\":N_DATA, \"N_EPOCHS\":N_EPOCHS, \"LEARNING_RATE\":LEARNING_RATE, \"PATIENCE\":PATIENCE, \"COOLDOWN\":COOLDOWN, \"FACTOR\":FACTOR, \"RTOL\":RTOL, \"ACCUMULATION_SIZE\":ACCUMULATION_SIZE, \"LEARNING_RATE_MIN\":LEARNING_RATE_MIN, \"BATCH_SIZE\":BATCH_SIZE, \"NUM_BATCH\":NUM_BATCH, \"NUM_CLASSES\":NUM_CLASSES, \"HIDDEN_SIZE\":HIDDEN_SIZE, \"NUM_LAYERS\":NUM_LAYERS, \"WDECAY\":WDECAY}\n",
    "                          #  \"ranks\": ranks, \"thetas_tilde\": thetas_tilde, \"thetas\": thetas}\n",
    "\n",
    "\n",
    "\n",
    "                NAME = \"GaussGauss_ndata_{}_sigma0_{}_mu_{:.3}_alpha_{:.3}_eps_{:.5}\".format(N_DATA, int(SIGMA0), TRUE_MU, ALPHA, EPSILON)\n",
    "                NAMEFILE = PATH_TRUE_MU+NAME+\".xy\"\n",
    "  \n",
    "                \n",
    "                with lzma.open(NAMEFILE, \"wb\") as f:\n",
    "                    pickle.dump(pickle_dico, f)\n",
    "                print(\"Data saved in \", NAMEFILE)\n",
    "                \n",
    "                \n",
    "                print(\"\\n\\n--------------------\")\n",
    "                print(\"ITERATION (ALPHA = {}) DONE IN {} SECONDS!\".format(ALPHA, time.time()-time_iter))\n",
    "                print(\"--------------------\\n\\n\")\n",
    "            dico_mu[\"PARAMS\"] = PARAMS\n",
    "            dico_mu[\"TEST_ACCURACY\"] = TEST_ACCURACY\n",
    "            name_dico_mu = \"GaussGauss_ndata_{}_sigma0_{}_mu_{:.3}\".format(N_DATA, int(SIGMA0), TRUE_MU)\n",
    "            with lzma.open(PATH_SIGMA0+name_dico_mu+\".xz\", \"wb\") as f:\n",
    "                pickle.dump(dico_mu, f)\n",
    "            print(\"Data saved in \", PATH_SIGMA0+name_dico_mu+\".xz\")\n",
    "            print(\"\\n\\n--------------------\\n\\n\")\n",
    "            \n",
    "            PARAMS_SIGMA0[i] = PARAMS\n",
    "            TEST_ACCURACY_SIGMA0[i] = TEST_ACCURACY\n",
    "            EPSILONS_SIGMA0[i] = EPSILONS\n",
    "            C2ST_ACCURACY_SIGMA0[i] = C2ST_ACCURACY\n",
    "            print(C2ST_ACCURACY_SIGMA0 )\n",
    "        dico_sigma0[\"C2ST_ACCURACY\"] = C2ST_ACCURACY_SIGMA0\n",
    "        dico_sigma0[\"PARAMS\"] = PARAMS_SIGMA0\n",
    "        dico_sigma0[\"TEST_ACCURACY\"] = TEST_ACCURACY_SIGMA0\n",
    "        dico_sigma0[\"EPSILONS\"] = EPSILONS_SIGMA0\n",
    "        dico_sigma0[\"TRUE_DATAS\"] = TRUE_DATAS\n",
    "        \n",
    "        name_dico_sigma0 = \"GaussGauss_ndata_{}_sigma0_{}\".format(N_DATA, int(SIGMA0))\n",
    "        with lzma.open(PATH_N_DATA+name_dico_sigma0+\".xz\", \"wb\") as f:\n",
    "            pickle.dump(dico_sigma0, f)\n",
    "        print(\"Data saved in \", PATH_N_DATA+name_dico_sigma0+\".xz\")\n",
    "        print(\"\\n\\n--------------------\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
